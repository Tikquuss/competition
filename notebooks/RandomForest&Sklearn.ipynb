{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp6x-UtmCoWj"
      },
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hnqkt7qjzrC5"
      },
      "outputs": [],
      "source": [
        "# %cd /content\n",
        "# ! rm -r competition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNiMQVlHv_mX"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/Tikquuss/competition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cvcNScroqJWo"
      },
      "outputs": [],
      "source": [
        "%cd competition/code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbUmFGg-MDmI"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrUFx-EWLPjX"
      },
      "outputs": [],
      "source": [
        "# Imports from our code\n",
        "from utils import DATA_PATH, DIR_PATH_FIGURES, DIR_PATH_SUBMISSIONS, H, W\n",
        "from utils import predict_nontest, predict_test, save_for_submission, eval\n",
        "from data import  get_dataset\n",
        "from plotter import plot_cdf, custom_imshow, confusion_matrix, scores, plot_confusion_matrix, show_example_images\n",
        "from model_tree import RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier as sklearn_RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KOrLK_1GDnjR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import tqdm\n",
        "import itertools\n",
        "from collections import Counter\n",
        "import time\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dJ1x63h0L-t"
      },
      "source": [
        "# Training & Validation & Test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYY2dbpkdm4G"
      },
      "source": [
        "**Normal training data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O04tPn2yudlF"
      },
      "outputs": [],
      "source": [
        "#HEIGHT, WIDTH = 60, 60\n",
        "#HEIGHT, WIDTH = 25, 25\n",
        "#HEIGHT, WIDTH = 10, 10\n",
        "HEIGHT, WIDTH = 5, 5\n",
        "#HEIGHT, WIDTH = None, None\n",
        "\n",
        "scaler_class=None\n",
        "#scaler_class='standard_scaler'\n",
        "scaler_class='min_max_scaler'\n",
        "\n",
        "train_pct, holdout_pct = 80, 10\n",
        "#train_pct, holdout_pct = 90, 10\n",
        "#train_pct, holdout_pct = 100,0\n",
        "\n",
        "seed=0\n",
        "n_classes=24"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEMuM8qLhtK0"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaQOVPIhzS7O"
      },
      "outputs": [],
      "source": [
        "IDs_test, (X_tr, Y_tr, X_ht_test, Y_ht_test, X_val, Y_val, X_all, Y_all, X_test, X_test_all, X_ht_test_all, d) = get_dataset(\n",
        "    train_pct=train_pct, holdout_pct=holdout_pct, k_fold=False, HEIGHT=HEIGHT, WIDTH=WIDTH, do_over_sampling=False, do_under_sampling=False,\n",
        "    scaler_class=scaler_class, is_pytorch=False, seed=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AN_xItp-4MAI"
      },
      "outputs": [],
      "source": [
        "print(X_all.min(), X_all.max())\n",
        "_=show_example_images(X_all.reshape(-1, H if HEIGHT is None else HEIGHT, W if HEIGHT is None else WIDTH), Y_all, n_imgs=15, mono = 'viridis')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8tZZvB3kmTu"
      },
      "source": [
        "**Training data for k-fold cross validation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5bA6bcpUkiEy"
      },
      "outputs": [],
      "source": [
        "# IDs_test, kfold_iterator = get_dataset(\n",
        "#     train_pct=train_pct, holdout_pct=holdout_pct, k_fold=True, HEIGHT=HEIGHT, WIDTH=WIDTH, do_over_sampling=False, do_under_sampling=False,\n",
        "#     scaler_class=scaler_class, is_pytorch=False, seed=seed\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e3dFcksTyJ_"
      },
      "source": [
        "# My random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mi6TtFu62fwg"
      },
      "outputs": [],
      "source": [
        "# : python train_tree.py --model_name test --n_estimators 100 --max_depth 100 --max_samples 1.0 --max_features sqrt --sklearn False --SIZE 28 --train_pct 90 --holdout_pct 10 --seed 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV4qqNoI2geh"
      },
      "source": [
        "**OR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTou4Zg-3Ocs"
      },
      "outputs": [],
      "source": [
        "fileName=\"test_random_forest\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-qRMX_ZT0ks"
      },
      "outputs": [],
      "source": [
        "forest = RandomForestClassifier(\n",
        "                 n_estimators=10,\n",
        "                 criterion='gini',\n",
        "                 max_depth=100,\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1,\n",
        "                 max_features='sqrt',\n",
        "                 max_leaf_nodes=None,\n",
        "                 min_impurity_decrease=0.0,\n",
        "                 bootstrap=True,\n",
        "                 random_state=None,\n",
        "                 verbose=0,\n",
        "                 max_samples=0.1,\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q77ytstGo8Jo"
      },
      "outputs": [],
      "source": [
        "if train_pct + holdout_pct < 100 : # validation data\n",
        "    forest.fit(X_tr, Y_tr)\n",
        "    train_acc = eval(forest, X_tr, Y_tr)\n",
        "    val_acc = eval(forest, X_val, Y_val)\n",
        "    test_acc = predict_nontest(forest, X_ht_test, Y_ht_test, seed=seed)\n",
        "\n",
        "    conf_matrix_1 = confusion_matrix(Y_tr, forest.predict(X_tr), n_classes=n_classes)\n",
        "    conf_matrix_2  = confusion_matrix(Y_ht_test, forest.predict(X_ht_test), n_classes=n_classes)\n",
        "\n",
        "    Y_hat_A, Y_hat_B = predict_test(forest, X_test)\n",
        "else : # No validation data\n",
        "\n",
        "    forest.fit(X_all, Y_all)\n",
        "    train_acc = eval(forest, X_all, Y_all)\n",
        "    val_acc = -1\n",
        "    test_acc = predict_nontest(forest, X_ht_test_all, Y_ht_test, seed=seed)\n",
        "\n",
        "    conf_matrix_1 = confusion_matrix(Y_all, forest.predict(X_all), n_classes=n_classes)\n",
        "    conf_matrix_2 = confusion_matrix(Y_ht_test, forest.predict(X_ht_test_all), n_classes=n_classes)\n",
        "\n",
        "    Y_hat_A, Y_hat_B = predict_test(forest, X_test_all)\n",
        "\n",
        "node_count = forest.node_count()\n",
        "\n",
        "print(\"train acc : {:7.4f} % \\nvalidation acc : {:7.4f} % \\nnumber of nodes  : {:7}\".format(train_acc * 100, val_acc * 100, node_count))\n",
        "print(\"test : \", test_acc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kc8jxB2GT63M"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(conf_matrix_1, fileName=f\"{fileName}_train\")\n",
        "_ = scores(conf_matrix_1, fileName=f\"{fileName}_train\")\n",
        "\n",
        "plot_confusion_matrix(conf_matrix_2, fileName=f\"{fileName}_test\")\n",
        "_ = scores(conf_matrix_2, fileName=f\"{fileName}_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFe6PdFeDolx"
      },
      "outputs": [],
      "source": [
        "save_for_submission(IDs_test, Y_hat_A, Y_hat_B, fileName=f\"{fileName}.csv\")\n",
        "i=0\n",
        "_=show_example_images(X_test[i].reshape(-1, H if HEIGHT is None else HEIGHT, W if HEIGHT is None else WIDTH), [Y_hat_A, Y_hat_B][i], n_imgs=15, mono = 'viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QsGNEqQz3azK"
      },
      "outputs": [],
      "source": [
        "with open(f\"{DIR_PATH_FIGURES}/{fileName}.pickle\" ,\"wb\") as file_handle:\n",
        "    to_save = {\n",
        "      \"model\" : forest,\n",
        "      \"perfs\" : [train_acc, val_acc, test_acc],\n",
        "      \"others\" : [conf_matrix_1, conf_matrix_2],\n",
        "      \"Y_hat_test\" : [Y_hat_A, Y_hat_B]\n",
        "    }\n",
        "    pickle.dump(to_save, file_handle, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JmaNozLdvIr"
      },
      "source": [
        "# New Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AnJMrpGdxZ2"
      },
      "outputs": [],
      "source": [
        "HEIGHT, WIDTH = None, None\n",
        "\n",
        "scaler_class=None\n",
        "#scaler_class='standard_scaler'\n",
        "scaler_class='min_max_scaler'\n",
        "\n",
        "train_pct, holdout_pct = 80, 10\n",
        "#train_pct, holdout_pct = 90, 10\n",
        "#train_pct, holdout_pct = 100,0\n",
        "\n",
        "seed=0\n",
        "n_classes=24\n",
        "\n",
        "IDs_test, (X_tr, Y_tr, X_ht_test, Y_ht_test, X_val, Y_val, X_all, Y_all, X_test, X_test_all, X_ht_test_all, d) = get_dataset(\n",
        "    train_pct=train_pct, holdout_pct=holdout_pct, k_fold=False, HEIGHT=HEIGHT, WIDTH=WIDTH, do_over_sampling=False, do_under_sampling=False,\n",
        "    scaler_class=scaler_class, is_pytorch=False, seed=seed\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GX2oDvNePbtk"
      },
      "source": [
        "# Sklearn random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cO3I8PW5XIe"
      },
      "outputs": [],
      "source": [
        "fileName=\"test_random_forest_sklearn\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZr0nkbmPdvT"
      },
      "outputs": [],
      "source": [
        "forest = sklearn_RandomForestClassifier(\n",
        "                 n_estimators=10,#0, #, # 128\n",
        "                 criterion='gini',\n",
        "                 max_depth=100, #None, # 8\n",
        "                 min_samples_split=2,\n",
        "                 min_samples_leaf=1,\n",
        "                 max_features='sqrt',\n",
        "                 max_leaf_nodes=None,\n",
        "                 min_impurity_decrease=0.0,\n",
        "                 bootstrap=True,\n",
        "                 random_state=0,\n",
        "                 verbose=0,\n",
        "                 max_samples=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOko_dJk4716"
      },
      "outputs": [],
      "source": [
        "if train_pct + holdout_pct < 100 : # validation data\n",
        "    forest.fit(X_tr, Y_tr)\n",
        "    train_acc = eval(forest, X_tr, Y_tr)\n",
        "    val_acc = eval(forest, X_val, Y_val)\n",
        "    test_acc = predict_nontest(forest, X_ht_test, Y_ht_test, seed=seed)\n",
        "\n",
        "    conf_matrix_1 = confusion_matrix(Y_tr, forest.predict(X_tr), n_classes=n_classes)\n",
        "    conf_matrix_2  = confusion_matrix(Y_ht_test, forest.predict(X_ht_test), n_classes=n_classes)\n",
        "\n",
        "    Y_hat_A, Y_hat_B = predict_test(forest, X_test)\n",
        "else : # No validation data\n",
        "\n",
        "    forest.fit(X_all, Y_all)\n",
        "    train_acc = eval(forest, X_all, Y_all)\n",
        "    val_acc = -1\n",
        "    test_acc = predict_nontest(forest, X_ht_test_all, Y_ht_test, seed=seed)\n",
        "\n",
        "    conf_matrix_1 = confusion_matrix(Y_all, forest.predict(X_all), n_classes=n_classes)\n",
        "    conf_matrix_2 = confusion_matrix(Y_ht_test, forest.predict(X_ht_test_all), n_classes=n_classes)\n",
        "\n",
        "    Y_hat_A, Y_hat_B = predict_test(forest, X_test_all)\n",
        "\n",
        "node_count = 0\n",
        "\n",
        "print(\"train acc : {:7.4f} % \\nvalidation acc : {:7.4f} % \\nnumber of nodes  : {:7}\".format(train_acc * 100, val_acc * 100, node_count))\n",
        "print(\"test : \", test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKO9bO4K5Kk0"
      },
      "outputs": [],
      "source": [
        "# plot_confusion_matrix(conf_matrix_1, fileName=f\"{fileName}_train\")\n",
        "# _ = scores(conf_matrix_1, fileName=f\"{fileName}_train\")\n",
        "\n",
        "# plot_confusion_matrix(conf_matrix_2, fileName=f\"{fileName}_test\")\n",
        "# _ = scores(conf_matrix_2, fileName=f\"{fileName}_test\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBPenpmcPmR6"
      },
      "outputs": [],
      "source": [
        "# save_for_submission(IDs_test, Y_hat_A, Y_hat_B, fileName=f\"{fileName}.csv\")\n",
        "# i=0\n",
        "#_ = show_example_images(X_test[i].reshape(-1, H if HEIGHT is None else HEIGHT, W if HEIGHT is None else WIDTH), [Y_hat_A, Y_hat_B][i], n_imgs=15, mono = 'viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rp29_-znPyWt"
      },
      "outputs": [],
      "source": [
        "# with open(f\"{DIR_PATH_FIGURES}/{fileName}.pickle\" ,\"wb\") as file_handle:\n",
        "#     to_save = {\n",
        "#       \"model\" : forest,\n",
        "#       \"perfs\" : [train_acc, val_acc, test_acc],\n",
        "#       \"others\" : [conf_matrix_1, conf_matrix_2],\n",
        "#       \"Y_hat_test\" : [Y_hat_A, Y_hat_B]\n",
        "#     }\n",
        "#     pickle.dump(to_save, file_handle, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2lgXcwx3eZk"
      },
      "source": [
        "# Hyperameter seachs Sklearn Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gg_mynY8JrQi"
      },
      "outputs": [],
      "source": [
        "fileName=\"test_random_forest_sklearn_hpsearch\"\n",
        "log_dir = Path(DIR_PATH_FIGURES).parent.absolute()\n",
        "\n",
        "log_dir = os.path.join(log_dir, f\"{fileName}\")\n",
        "DIR_PATH_FIGURES__ = os.path.join(log_dir, \"figures\")\n",
        "DIR_PATH_SUBMISSIONS__ = os.path.join(log_dir, \"submissions\")\n",
        "os.makedirs(DIR_PATH_SUBMISSIONS__, exist_ok=True)\n",
        "os.makedirs(DIR_PATH_FIGURES__, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alZe3lBR3gpO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\"\n",
        "m : the number of trees\n",
        "r : maximum depth\n",
        "n_prime : number of samples to draw to train each base tree\n",
        "d_prime : number of features to consider for each tree  ($d' = \\lfloor \\sqrt{d} \\rfloor$ ...)\n",
        "f  : purity criteria (Gini index or entropy).\n",
        "\"\"\"\n",
        "\n",
        "all_m = np.array([1,  10])\n",
        "all_r = np.array([10,  50])\n",
        "all_n_prime = [0.1, 1.0]\n",
        "all_d_prime = [28, 1.0] # 28 = sqrt(d)\n",
        "#all_f = [\"gini\", \"entropy\"]\n",
        "all_f = [\"gini\"]\n",
        "\n",
        "# all_m = np.array([1,  50,  100, 200, 300])\n",
        "# all_r = np.array([10,  100, 150, 200, 300])\n",
        "# all_n_prime = [0.1, 0.5,  1.0]\n",
        "# all_d_prime = [28, 0.5, 1.0] # 28 = sqrt(d)\n",
        "# #all_f = [\"gini\", \"entropy\"]\n",
        "# all_f = [\"gini\"]\n",
        "\n",
        "all_hparams = itertools.product(all_m, all_r, all_n_prime, all_d_prime, all_f)\n",
        "all_hparams = list(all_hparams)\n",
        "len(all_hparams)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONanG5g9c3Xh"
      },
      "outputs": [],
      "source": [
        "all_performances = {}\n",
        "all_models = {}\n",
        "\n",
        "for m, r, n_prime, d_prime, f in tqdm.tqdm(all_hparams, desc=\"Hyp search\") :\n",
        "\n",
        "    train_start = time.time()\n",
        "\n",
        "    forest = sklearn_RandomForestClassifier(\n",
        "                    n_estimators=m, # m\n",
        "                    criterion=f, # f\n",
        "                    max_depth=r, # r\n",
        "                    min_samples_split=2,\n",
        "                    min_samples_leaf=1,\n",
        "                    max_features=d_prime, # d'\n",
        "                    max_leaf_nodes=None,\n",
        "                    min_impurity_decrease=0.0,\n",
        "                    bootstrap=True,\n",
        "                    random_state=0,\n",
        "                    verbose=0,\n",
        "                    max_samples=n_prime # n'\n",
        "                    )\n",
        "\n",
        "\n",
        "    forest.fit(X_tr, Y_tr)\n",
        "    train_acc = eval(forest, X_tr, Y_tr)\n",
        "    val_acc = eval(forest, X_val, Y_val)\n",
        "\n",
        "    training_time = time.time() - train_start\n",
        "\n",
        "    # m, r, n_prime, d_prime, f\n",
        "    key = f\"m={m}_r={r}_n'={n_prime}_d'={d_prime}_f={f}\"\n",
        "    print(\"\\n\", key, train_acc * 100, val_acc * 100, training_time)\n",
        "\n",
        "    all_models[key] = forest\n",
        "    all_performances[key] = [train_acc, val_acc]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3mk_F_UC5LaU"
      },
      "outputs": [],
      "source": [
        "with open(f\"{log_dir}/all_performances_sktree.pickle\",\"wb\") as file_handle:\n",
        "    pickle.dump(all_performances, file_handle, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open(f\"{log_dir}/all_models_sktree.pickle\",\"wb\") as file_handle:\n",
        "    pickle.dump(all_models, file_handle, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjgRbalPjoVg"
      },
      "outputs": [],
      "source": [
        "rows, cols = 1, 1\n",
        "figsize = (6, 4)\n",
        "figsize=(cols*figsize[0], rows*figsize[1])\n",
        "fig = plt.figure(figsize=figsize)\n",
        "ax = fig.add_subplot(rows, cols, 1)\n",
        "\n",
        "values = np.array(list(all_performances.values()))\n",
        "values = [values[:,0], values[:,1]]\n",
        "for v, model_name in zip(values, ['training', 'validation']) :\n",
        "    ax.hist(x=v,\n",
        "        label=model_name, color=None,\n",
        "        histtype='step',\n",
        "        align='mid',\n",
        "        orientation='vertical',\n",
        "        log=False,\n",
        "        stacked=False,\n",
        "        density=True,\n",
        "        rwidth=None,\n",
        "        #rwidth=0.8,\n",
        "    )\n",
        "\n",
        "ax.grid()\n",
        "ax.legend(prop={'size': 15})\n",
        "\n",
        "fileName=f\"histogramm_perf\"\n",
        "plt.savefig(f\"{DIR_PATH_FIGURES__}/{fileName}\"  + '.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
        "#print(fileName)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB4w6bZh_Vew"
      },
      "outputs": [],
      "source": [
        "x = np.array(list(all_performances.values()))[:,0]\n",
        "_ = plot_cdf(x, fileName=\"hp_search_sktree_cdf_train\", dpf=DIR_PATH_FIGURES__)\n",
        "#plt.close()\n",
        "x = np.array(list(all_performances.values()))[:,1]\n",
        "_ = plot_cdf(x, fileName=\"hp_search_sktree_cdf_val\", dpf=DIR_PATH_FIGURES__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr3Wf5vsPj-2"
      },
      "outputs": [],
      "source": [
        "all_n_prime_d_prime = list(itertools.product(all_n_prime, all_d_prime))\n",
        "all_n_prime_d_prime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x16Vwdys_KOf"
      },
      "outputs": [],
      "source": [
        "n_imgs=len(all_n_prime_d_prime)\n",
        "\n",
        "L=3\n",
        "C=n_imgs//L + 1*(n_imgs%L!=0)\n",
        "\n",
        "C=3\n",
        "L=n_imgs//C + 1*(n_imgs%C!=0)\n",
        "\n",
        "figsize=(C*15, L*10)\n",
        "#figsize=(C*6, L*4)\n",
        "fig = plt.figure(figsize=figsize)\n",
        "\n",
        "train_or_val = 0 # train\n",
        "train_or_val = 1 # vam\n",
        "values =  np.array(list(all_performances.values()))[:,train_or_val]\n",
        "factor = 100\n",
        "minmin = factor*min(values)\n",
        "maxmax = factor*max(values)\n",
        "\n",
        "axlist = []\n",
        "iii = 0\n",
        "for n_prime, d_prime in all_n_prime_d_prime[:L*C] :\n",
        "    ax = fig.add_subplot(L, C, iii+1)\n",
        "\n",
        "    # gamma : all_m\n",
        "    # lrs : all_r\n",
        "    img_data = np.empty((len(all_m), len(all_r)))\n",
        "    for i, m in enumerate(all_m) :\n",
        "        for j, r in enumerate(all_r) :\n",
        "            f = \"gini\"\n",
        "            img_data[i][j] = all_performances[f\"m={m}_r={r}_n'={n_prime}_d'={d_prime}_f={f}\"][train_or_val]\n",
        "\n",
        "    img_data = img_data*factor\n",
        "\n",
        "    #print(img_data)\n",
        "    imshow_kwarg = {'vmin':minmin, 'vmax':maxmax,\n",
        "                    #\"extent\":(-5,5,-5,5),\n",
        "                    \"aspect\":'auto'}\n",
        "    img = custom_imshow(img_data,\n",
        "                  ax=ax, fig=fig,\n",
        "                  add_text=True, n_decimals=2,\n",
        "                  yticklabels=all_m,\n",
        "                  xticklabels=all_r,\n",
        "                  y_label=\"number of trees\", x_label=\"maximum depth\",\n",
        "                  rotation_x=90, rotation_y=0,\n",
        "                  imshow_kwarg = imshow_kwarg,\n",
        "                  colorbar = False,\n",
        "                  show=False,\n",
        "                  #fileName=f\"m_vs_r_hpsearch_sklearn\"\n",
        "                  )\n",
        "\n",
        "    ax.set_title(f\"(n', d')=({n_prime}, {d_prime})\", fontsize=30, loc='right', y=-0.1)#, y=0.5, pad=-15, )\n",
        "\n",
        "    axlist.append(ax)\n",
        "    iii+=1\n",
        "\n",
        "fig.colorbar(img, ax=axlist, fraction=0.046, pad=0.04, aspect=60, location=\"top\")\n",
        "\n",
        "fileName=f\"m_vs_r_hpsearch_sklearn_{'train' if train_or_val==0 else 'val'}\"\n",
        "plt.savefig(f\"{DIR_PATH_FIGURES__}/{fileName}\"  + '.pdf', dpi=300, bbox_inches='tight', format='pdf')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxNtXHUkHzu6"
      },
      "outputs": [],
      "source": [
        "kv = {k:v[1] for k, v in all_performances.items()} # val\n",
        "hparam_best = max(kv, key=all_performances.get)\n",
        "hparam_best, all_performances[hparam_best]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hfWNMNlBRrk"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier as sklearn_RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-7hPnlLH5GB"
      },
      "outputs": [],
      "source": [
        "m=200\n",
        "r=100\n",
        "n_prime=1.0\n",
        "d_prime=28\n",
        "f=\"gini\"\n",
        "forest = sklearn_RandomForestClassifier(\n",
        "                n_estimators=m, # m\n",
        "                criterion=f, # f\n",
        "                max_depth=r, # r\n",
        "                min_samples_split=2,\n",
        "                min_samples_leaf=1,\n",
        "                max_features=d_prime, # d'\n",
        "                max_leaf_nodes=None,\n",
        "                min_impurity_decrease=0.0,\n",
        "                bootstrap=True,\n",
        "                random_state=0,\n",
        "                verbose=0,\n",
        "                max_samples=n_prime # n'\n",
        "                )\n",
        "\n",
        "\n",
        "forest.fit(X_all, Y_all)\n",
        "train_acc = eval(forest, X_all, Y_all)\n",
        "val_acc = -1\n",
        "test_acc = predict_nontest(forest, X_ht_test_all, Y_ht_test, seed=seed)\n",
        "\n",
        "conf_matrix_1 = confusion_matrix(Y_all, forest.predict(X_all), n_classes=n_classes)\n",
        "conf_matrix_2 = confusion_matrix(Y_ht_test, forest.predict(X_ht_test_all), n_classes=n_classes)\n",
        "\n",
        "Y_hat_A, Y_hat_B = predict_test(forest, X_test_all)\n",
        "\n",
        "print(train_acc * 100, val_acc*100, test_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNxS-6JKI6oa"
      },
      "outputs": [],
      "source": [
        "plot_confusion_matrix(conf_matrix_1, fileName=f\"{fileName}_train\", dpf=DIR_PATH_FIGURES__)\n",
        "_ = scores(conf_matrix_1, fileName=f\"{fileName}_train\", dpf=DIR_PATH_FIGURES__)\n",
        "\n",
        "plot_confusion_matrix(conf_matrix_2, fileName=f\"{fileName}_test\", dpf=DIR_PATH_FIGURES__)\n",
        "_ = scores(conf_matrix_2, fileName=f\"{fileName}_test\", dpf=DIR_PATH_FIGURES__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8DRnHUHO808"
      },
      "outputs": [],
      "source": [
        "save_for_submission(IDs_test, Y_hat_A, Y_hat_B, fileName=f\"{fileName}.csv\", dps=DIR_PATH_SUBMISSIONS__)\n",
        "i=0\n",
        "_=show_example_images(X_test[i].reshape(-1, H if HEIGHT is None else HEIGHT, W if HEIGHT is None else WIDTH), [Y_hat_A, Y_hat_B][i], n_imgs=15, mono = 'viridis')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VR3ZLV0LO3xQ"
      },
      "outputs": [],
      "source": [
        "with open(f\"{DIR_PATH_FIGURES__}/{fileName}.pickle\" ,\"wb\") as file_handle:\n",
        "    to_save = {\n",
        "      \"model\" : forest,\n",
        "      \"perfs\" : [train_acc, val_acc, test_acc],\n",
        "      \"others\" : [conf_matrix_1, conf_matrix_2],\n",
        "      \"Y_hat_test\" : [Y_hat_A, Y_hat_B]\n",
        "    }\n",
        "    pickle.dump(to_save, file_handle, pickle.HIGHEST_PROTOCOL)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k97er-nl8YZJ"
      },
      "source": [
        "# Other Sklearn methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AJ4vu5P8abM"
      },
      "outputs": [],
      "source": [
        "# ! pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_i3YXla8ZcP"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, ComplementNB\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.cluster import KMeans\n",
        "from xgboost import XGBClassifier\n",
        "import xgboost\n",
        "\n",
        "from sklearn.ensemble import  ExtraTreesClassifier, GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier as sklearn_RandomForestClassifier\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qsy92dAg8gUC"
      },
      "outputs": [],
      "source": [
        "def train_and_plot_sklean(sk_model) :\n",
        "    \"\"\"forest, Y_hat_test, strain, s_ht_test = train_and_plot_sklean(sk_model)\"\"\"\n",
        "    clf = sk_model.fit(X_all, Y_all)\n",
        "    strain, s_ht_test = clf.score(X_all, Y_all), clf.score(X_ht_test_all, Y_ht_test)\n",
        "    print(strain, s_ht_test)\n",
        "    Y_hat_test = clf.predict(X_ht_test_all)\n",
        "    #print(Counter(Y_hat_test))\n",
        "    return clf, Y_hat_test, strain, s_ht_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-W1PA-38mPe"
      },
      "outputs": [],
      "source": [
        "# https://www.kaggle.com/code/davidfumo/comparing-11-classification-models\n",
        "classifiers = [\n",
        "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
        "    #SVC(gamma='auto', probability=True), # 2\n",
        "    LinearSVC(),\n",
        "    #LogisticRegression(random_state=0), # 4\n",
        "    #KNeighborsClassifier(3),\n",
        "    DecisionTreeClassifier(),\n",
        "    RandomForestClassifier(),\n",
        "    XGBClassifier(),\n",
        "    AdaBoostClassifier(),\n",
        "    GradientBoostingClassifier(), # 1\n",
        "    GaussianNB(), # 5\n",
        "    LinearDiscriminantAnalysis(),\n",
        "    QuadraticDiscriminantAnalysis(),\n",
        "    MLPClassifier(\n",
        "        hidden_layer_sizes=(d, 500, n_classes), activation='relu', solver='adam', alpha=0.0001,\n",
        "        batch_size=X_tr.shape[0],\n",
        "        learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=100,\n",
        "        shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
        "        nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
        "        epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
        "    ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGwM35MXPKmC"
      },
      "outputs": [],
      "source": [
        "# Logging for Visual Comparison\n",
        "log_cols=[\"Classifier\", \"Training set\", \"Holdout test set\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        "all_clf = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqnu7Iqd83NV"
      },
      "outputs": [],
      "source": [
        "for sk_model in classifiers:\n",
        "    clf, Y_hat_test, strain, s_ht_test = train_and_plot_sklean(sk_model)\n",
        "\n",
        "    name = clf.__class__.__name__\n",
        "    while name in all_clf.keys() : name += \"_1\"\n",
        "    print(name)\n",
        "    all_clf[name] = clf\n",
        "\n",
        "    log_entry = pd.DataFrame([[name, strain, s_ht_test]], columns=log_cols)\n",
        "    log = log.append(log_entry)\n",
        "\n",
        "    print(\"=\"*30)\n",
        "\n",
        "print(\"=\"*30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7nx3WTB88Hk"
      },
      "outputs": [],
      "source": [
        "log_sort = log.sort_values(by=['Holdout test set'], ascending=False)\n",
        "for index, row in log_sort.iterrows() :\n",
        "    print(f\"{row['Classifier']} & {round(row['Training set']*100, 2)} & {round(row['Holdout test set']*100, 2)} \\\\\\ \\hline\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZd_e2y_8_6o"
      },
      "outputs": [],
      "source": [
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x=\"Training set\", y='Classifier', data=log_sort, color=\"b\")\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.title('Training set')\n",
        "plt.show()\n",
        "\n",
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x=\"Holdout test set\", y='Classifier', data=log_sort, color=\"b\")\n",
        "plt.xlabel(\"Accuracy\")\n",
        "plt.title('Holdout test set')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLQKOaJY9N9R"
      },
      "outputs": [],
      "source": [
        "all_Y = []\n",
        "for k, clf in all_clf.items() :\n",
        "    s_ht_test = clf.score(X_ht_test_all, Y_ht_test)\n",
        "    print(k, s_ht_test)\n",
        "    Y_hat_test = clf.predict(X_ht_test_all)\n",
        "    all_Y.append(Y_hat_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
